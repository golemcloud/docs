import { Callout } from "nextra/components"
import { Card, Cards } from "nextra/components"

## Reliability

Golem is a durable computing platform that makes it simple to build and
deploy highly reliabile distributed systems.

When developing for Golem, you normally don't need to worry about most of  
the complexity of ensuring reliable execution. Golem takes care of the heavy
lifting for you, ensuring that your applications are resilient, robust,
fault-tolerant, and highly available.

However, when evaluating Golem for your use case, it is essential to understand
exactly what guarantees Golem provides, what you need to handle on your own,
and how you can tune Golem to meet your specific requirements.

In this section, we'll explore all of these aspects in detail, starting with
the essential concepts of reliability in distributed systems.

## Essential Concepts

In the field of distributed systems, several technical concepts are crucial to
the development of reliable solutions:

1. **Resiliency**: The system's ability to correctly identify and respond to
   failures in external dependencies.
2. **Robustness**: The system's capacity to prevent, identify, and correctly
   respond to internal failures.
3. **Fault-Tolerance**: The system's ability to continue functioning correctly
   even when experiencing one or more faults.
4. **High-Availability**: The system's capability to remain available and
   responsive under various conditions, including partial failures or high stress.

Let's explore each of these concepts in detail to understand how they
contribute to overall system reliability.

### Resiliency

Resiliency is the ability of a system to continue functioning correctly even in
the presence of failures in the systems it interacts with.

Modern systems interact with numerous remote components through network
protocols. These external systems can fail in various ways, presenting
challenges for maintaining overall system reliability.

Common types of external failures include:

- **Network Failures**: Disruptions in connectivity, degraded performance, or
  unstable connections preventing reliable communication.
- **Internal Failures in Remote Systems**: Bugs, crashes, or other malfunctions
  within external systems causing incorrect behavior or non-responsiveness.
- **Load-Related Failures**: Overwhelmed systems leading to degraded performance
  or total unavailability.
- **Maintenance-Related Downtime**: Planned or unplanned system updates,
  migrations, or other maintenance activities causing temporary unavailability.
- **API Versioning Incompatibilities**: Mismatches between different versions of
  interacting systems or APIs leading to errors or unpredictable outcomes.
- **Authorization and Authentication Issues**: Invalid credentials,
  insufficient permissions, or other access-related problems.

Highly resilient systems employ various strategies to handle these external
failures:

1. **Intelligent Retry Mechanisms**: Implementing advanced retry policies,
   often combining exponential backoff with random jitter to handle transient
   failures gracefully.
2. **Circuit Breaker Pattern**: Temporarily disabling calls to failing services
   to prevent cascading failures.
3. **Bulkhead Pattern**: Isolating components to ensure that failures in one
   part of the system don't bring down the entire application.

### Robustness

Robustness is the ability of a system to both prevent, as well as identify and
correctly respond to, failures of the system itself.

Internal failure scenarios can be categorized into a hierarchy, ranging from
business logic issues to infrastructure problems:

- **Defect Failures**: Errors due to software defects, such as null pointer
  exceptions, buffer overflows, or division by zero.
- **Domain Failures**: Failures to handle scenarios anticipated and specified
  by the business logic.
- **Unrecoverable Failures**: Situations where the software cannot recover,
  such as database access failures due to incorrect configuration.
- **OS Faults**: Operating system interference with process execution.
- **Hardware Faults**: Failures in critical hardware components like RAM,
  CPU, or network interfaces.

Strategies for improving robustness include:

1. **Comprehensive Error Handling**: Implementing thorough error handling
   covering various failure scenarios.
2. **Graceful Degradation**: Allowing systems to continue operating with
   reduced functionality rather than complete shutdown when encountering
   non-critical failures.
3. **Rapid Failure Detection**: Quickly identifying and reporting internal
   failures to enable fast resolution.

### Fault-Tolerance

Fault-tolerant systems are designed to continue functioning correctly even in
the presence of one or more faults. Fault-tolerance can be considered a
specific type of robustness, focusing on a system's ability to handle systemic
issues.

Strategies for fault-tolerant systems include:

1. **Replication**: Duplicating critical components across multiple nodes to
   ensure continued operation if some nodes fail.
2. **State Management**: Implementing robust state management tools to allow
   systems to recover gracefully from failures without data loss.
3. **Failover Mechanisms**: Automatically redirecting traffic to healthy nodes
   in case of node failures.

### High-Availability

High-availability systems are designed to be accessible and responsive to their
intended workloads, even under conditions of partial failure or stress.

Strategies for achieving high availability include:

1. **Load Balancing**: Distributing traffic across multiple instances to
   prevent any single point of failure.
2. **Auto-Scaling**: Automatically adjusting resources based on demand to
   ensure optimal performance during peak times.
3. **Geographic Distribution**: Deploying across multiple geographic regions
   to reduce latency and improve resilience against regional outages.

## Reliability: Bringing It All Together

Reliability is a comprehensive term that encompasses all of the preceding
concepts. A _highly reliable_ system is one that is:

- Resilient to external failures
- Robust in handling internal failures
- Fault-tolerant to systemic issues
- Highly available under various conditions

By addressing each of these aspects, developers can create distributed systems
that ensure data integrity, maintain consistent performance, and provide a
seamless experience for end-users, even in the face of various challenges and
failure scenarios.

# High-Reliability with Golem

With any programming language, tech stack, or SDK, Golem automatically provides
you with a high degree of built-in reliability.

These guarantees are summarized as follows:

- **Transactional execution**. Golem ensures that your workers execute
  transactionally. Once they begin execution, they will complete execution,
  even if there are software or hardware faults, restarts, or updates.
- **Durable state**. Golem ensures that the state of your workers is durable.
  If a worker is recovered after a failure, it will resume with the same state
  as before the failure.
- **Reliable internal communication**. Golem ensures that communication
  between workers is delivered reliably. If a message is sent, it will
  eventually be delivered, with exactly-once semantics; even if there are
  network partitions, faults, or other failures.
- **Resilient external communication**. Golem automatically applies retry
  strategies and other techniques to ensure that transient failures of
  external systems do not affect reliability.

In the following sections, we will explore these guarantees in more detail,
looking at how each of them improves different faucets of reliability.

## Resiliency

As discussed in [Components](concepts-components.mdx), all components deployed 
on Golem ultimately derive their capability to interact with external systems 
from _WASI_, which is the Posix-like interface provided by the WASM component 
model.

WASI provides facilities to interact with file systems, sockets, time, and other
system resources in a portable and secure manner.

Because Golem provides a custom implementation of WASI, it has direct insight 
into the interactions between components and the underlying system. This allows 
Golem to detect a variety of transient failure scenarios and automatically 
apply resiliency strategies, such as retries, to ensure that the system remains 
resilient to these failures.

Golem automatically applies retry strategies to the following types of failures:

 - TODO: 

In the case of errors which are not resolved on their own, Golem will 
eventually give up and mark the worker as failed. This is to prevent the 
system from getting stuck in an infinite loop of retries.

These workers can be detected using worker enumeration.

### Limitations 

Golem does not have awareness into transient errors that are expressed in protocol-
agnostic ways. For example, if an HTTP response contains a 200 status code, but 
the body contains a transient error, then Golem will not be able to detect this
error and attempt recovery.

You should be aware of this limitation when designing your applications, and
consider implementing your own retry strategies for such cases.

### Tuning

Currently, customizing the retry strategy cannot be done without forking the Golem 
source code. However, configuration-based retry strategies are on the roadmap.

## Robustness



## Fault-Tolerance

## High-Availability
