import { Tabs } from "nextra/components"

# Talking to Large Language Models

Golem provides a [library called golem-llm](https://github.com/golemcloud/golem-llm) that is a WebAssembly Component allowing Golem components written in any of the supported languages to use a set of supported LLM providers.

The current list of supported LLMs are the following:

- [Anthropic (Claude)](https://www.anthropic.com)
- [xAI (Grok)](https://x.ai)
- [OpenAI](https://openai.com)
- [OpenRouter](https://openrouter.ai)

The library contains a [WIT interface](https://github.com/golemcloud/golem-llm/blob/main/wit/golem-llm.wit) providing a unified interface for all these providers.

## Starting with the LLM templates

## Adding LLM support to an existing component

## Using the library
